# 27 | 决策树：信息增益、增益比率和基尼指数的运用

## 如何通过信息熵挑选合适的问题？

分三个步骤

1. 根据分组中的人物类型，为每个集合计算信息熵，并通过全部集合的熵值加权平均，获得整个数据集的熵。注意，一开始集合只有一个，并且包含了所有的武侠人物。
2. 根据信息增益，计算每个问卷题的区分能力。挑选区分能力最强的题目，并对每个集合进行更细的划分。
3. 有了新的划分之后，回到第一步，重复第一和第二步，直到没有更多的问卷题，或者所有的人物类型都已经被区分开来。这一步也体现了递归的思想。

述这个过程就体现了训练决策树（Decision Tree）的基本思想。

决策树的三个步骤

1. 根据集合中的样本分类，为每个集合计算信息熵，并通过全部集合的熵之加权平均，获得整个数据集的熵。注意，一开始集合只有一个，并且包含了所有的样本。
2. 根据信息增益，计算每个特征的区分能力。挑选区分能力最强的特征，并对每个集合进行更细的划分。
3. 有了新的划分之后，回到第一步，重复第一步和第二步，直到没有更多的特征，或者所有的样本都已经被分好类。

## 几种决策树算法的异同

**ID3** 采用信息增益来构建决策树的算法被称为ID3（Iterative Dichotomiser 3，迭代二叉树 3 代）

缺点： 由于 ID3 算法会优先考虑有较多取值的特征，因为这样可以将数据样本划分成更多小组，这样熵就可以大幅下降，信息增益则大幅提升。过多分组会导致机器学习中的拟合问题，不利于决策树对新数据的预测。

**C4.5** 该算法使用信息增益率（Information Gain Ratio）来替代信息增益，作为选择特征的标准，并降低决策树过拟合的程度。

信息增益率通过引入一个被称作分裂信息（Split Information）的项来惩罚取值较多的特征。

**CART 算法**（Classification and Regression Trees，分类与回归树）。

这种算法和 ID3、C4.5 相比，主要有两处不同：

1. 在分类时，CART 不再采用信息增益或信息增益率，而是采用基尼指数（Gini）来选择最好的特征并进行数据的划分；
2. 在 ID3 和 C4.5 决策树中，算法根据特征的属性值划分数据，可能会划分出多个组。而 CART 算法采用了二叉树，每次把数据切成两份，分别进入左子树、右子树。

