# 语言模型：如何使用链式法则和马尔科夫假设简化概率模型？
## 回顾几个概念
### 边缘概率
- P(A) P(B)这些与单个条件有关的概率
### 联合概率
- P(AB) 包含多个条件同时成立的概率 属于A B 的交集
### 条件概率
- 事件A在另外一个事件B已经发生条件下的发生概率 记为 P(A|B)
-  在B的条件下A的概率
-  条件概率 = 联合概率/边缘概率      P(A|B) = P(AB) / P(B)
-  如果 把A 和 B 看做图的话，P(A|B) 就是 AB相交的面积在B中的占比
### [全概率](httPs://baike.baiAu.com/item/%E5%85%A8%E6%A6%82%E7%8E%87%E5%85%AC%E5%BC%8F/9980676)
### 贝叶斯公式
-   用来描述两个条件概率之间的关系
-  P(AB) = P(A|B) * P(B)  = P(B|A) * P(A)
-  变异 P(A|B) =P(B|A) * P(A) / P(B) 画图出来很好理解的
## 本节内容
### 链式法则
-  P(x1,x2,x3.....xn) = p(x1) * p(x2|x1) * p(x3|x1x2) * ..... p(xn | x1....xn-1) 
### 马尔科夫假设
-  假设: 任何一个词 xi​ 出现的概率只和它前面的 1 个或若干个词有关
#### 二元文法
-	二元文法模型为例，来给你解释。按照刚才的说法，二元文法表示，某个单词出现的概率只和它前面的 1 个单词有关。也就是说，即使某个单词出现在一个很长的句子中，我们也只需要看前面那 1 个单词， p(xn|x1,x2,...xn-1) 约等于 p(xn|xn-1)
-	假设我们有一个统计样本文本 A，s 表示某个有意义的句子，由一连串按照特定顺序排列的词 x1​，x2​,…,xn​ 组成，这里 n 是句子里单词的数量。现在，我们想知道根据文档 A 的统计数据，s 在文本中出现的可能性，即 P(s∣A)，那么我们可以把它表示为 P(s∣A)=P(x1​,x2​,…,xn​∣A)。假设我们这里考虑的都是在集合 A 的情况下发生的概率，所以可以忽略 A，写为 P(s)=P(x1​,x2​,…,xn​)。到这里，我们碰到了第一个难题，就是如何计算

				P(x1,x2,x3.....xn) = p(x1) * p(x2|x1) * p(x3|x1x2) * ..... p(xn | x1....xn-1)
- 一直到 P(wn​∣w1​,w2​,…,wn−1​)，基本上又为 0 了,需要使用多元文法简化


				P(x1,x2,x3.....xn) 约等于 p(x1) * p(x2|x1) * p(x3|x1x2) * P(x4|x3, x2) * ..... p(xn | xn-1,xn-2)

### 语言模型的应用
#### 信息检索
-	种常见的做法是计算 P(A∣B)，其中 B 表示一个查询，A表示一篇文档。P(A∣B) 表示用户输入查询 B 的情况下，文档 A 出现的概率是多少？如果这个概率越高，我们就认为 B 和 A 之间的相关性越高
-	P(A|B) =P(B|A) * P(A) / P(B)
- 对于同一个查询，其出现概率 P(B) 都是相同的，同一个文档 A 的出现概率 P(A) 也是固定的。因此它们可以忽略，我们只要关注如何计算 P(B∣A)。而语言模型，为我们解决了如何计算 P(B∣A) 的问题，让 k1​,k2​,…,kn​ 表示查询 B 里包含的 n 个关键词。那么根据之前的链式法则公式，可以重写为这样：
-	p(B|A) = p(k1​,k2​,…,kn|A)假设是三元文法，那么我们可以写成这样：

			p(B|A) = p(k1​,k2​,…,kn|A) = p(k1|A) * p(k2|k1,A) * p(k3|k2,k1,A) * ... * p(kn | kn-1, kn-2, A)

######	不同的分词方法，导致了不同的p(B),  感觉只理解基础的，对于实际应用还是很欠缺，一知半解
