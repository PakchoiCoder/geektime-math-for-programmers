# 奇异值分解：如何挖掘潜在的语义关系？
- PCA的分解要求矩阵必须是对称的方阵，因此只适用于刻画特征之间关系的协方差矩阵，但是，有的时候我们需要挖掘的是样本和特征之间的关系，例如文档和词条。这个时候矩阵并不是对称的方阵，因此无法直接使用 PCA 分析。
- SVD 奇异值分解提供了一种可行的方案。它巧妙地运用了矩阵 X 和自己的转置相乘，生成了两种对称的方阵，并通过这两者的特征分解，获得了 SVD 中的左奇异向量所组成的矩阵 U 和右奇异向量所组成的矩阵 V，并最终推导出奇异值矩阵Σ。这样，SVD 就可以对原始的数据矩阵进行分解，并运用最终的奇异向量进行降维。

### 在语义分析 LSA
- 分析文档集合，建立表示文档和词条关系的矩阵。
- 对文档 - 词条矩阵进行 SVD 奇异值分解。在 LSA 的应用场景下，分解之后所得到的奇异值σ对应了一个语义上的“概念”，而 σ 值的大小表示这个概念在整个文档集合中的重要程度。U 中的左奇异值向量表示了每个文档和这些语义“概念”的关系强弱，V 中的右奇异值向量表示每个词条和这些语义“概念”的关系强弱。所以说，SVD 分解把原来的词条 - 文档关系，转换成了词条 - 语义概念 - 文档关系。
- 对 SVD 分解后的矩阵进行降维，这个操作和 PCA 主成分分析的降维操作是类似的。
- 使用降维后的矩阵重新构建概念 - 文档矩阵，新矩阵中的元素不再表示词条是不是出现在文档中，而是表示某个概念是不是出现在文档中。

