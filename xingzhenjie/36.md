# 36 | 文本聚类：如何过滤冗余的新闻？

## 聚类算法

监督式学习通过训练资料学习建立一个模型，并依此模型对新的实例进行预测。

实际场景中，存在更复杂的情况。不存在任何关于样本的先验知识，而是需要机器在没人指导的情形下。去将很多东西进行归类。由于缺乏训练样本，这种学习被称为“非监督学习”，也就是通常说的聚类。在这种学习体系中，系统必须通过一种有效的方法发现样本的内在相似性，并把数据对象以群组的形式进行划分。

K均值聚类算法，它让我们可以在一个任意多的数据上，得到一个事先定好群组数量（K）的聚类结果。

中心思想：尽量最大化总的群组内相似度，同时尽量最小化群组之间的相似度。群组内或群组间的相似度，是通过各个成员和群组质心相比较来确定的。

样本数量达到一定规模后，排列组合所有的群组划分，几乎不可能。需用求近似解的方法：

1. 从N个数据对象中随机选取k个对象作为质心，这里诶个群组的质心定义是，群组内所有成员对象的平均值。因为是第一轮，所以第i个群组的质心就是第i个对象，而且这时只有一个组员。
2. 对剩余的对象，测量它和每个质心的相似度，并把它归到最近的质心所属的群组。这里我们可以说距离，也可以说相似度，只是两者呈现反比关系。
3. 重新计算已经得到的各个群组的质心。这里质心的计算是关键，如果使用特征向量来表示的数据对象，那么最基本的方法是取群组内成员的特征向量，将它们的平均值作为质心的向量表示。
4. 迭代上面的第2步和第3步，直至新的质心与原质心相等或相差之值小于制定的阈值，算法结束。

**K均值算法是通过不断迭代、调整K个聚类质心的算法。而质心或者群组的中心点，是通过求群组所包含的成员之平均值来计算的。**

## 使用向量空间进行聚类

对新闻进行聚类，将内容非常类似的会被聚类到同一个分组，然后对这个分组之选择1-2个内容显示。

整个方法分为三个步骤：

第一步，把文档集合都转换成向量的形式。

第二步，使用K均值算法对文档集合进行聚类。

第三步，在每个分类中，选出和质心最接近的数个内容作为代表。其他内容作为冗余过滤掉。

## Python中的K均值算法

Scilit-learn是Python常用的机器学习库，它提供了大量的机器学习算法的实现和相关的文档，甚至还内置了一些公开数据集。


********









