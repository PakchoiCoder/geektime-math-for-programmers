# 29 | 归一化和标准化：各种特征如何综合才是最合理的？

## 为什么需要特征变换？

许多机器学习算法中都会使用特征变换

之前介绍的监督式学习会根据某个样本的一系列特征，最后判定它应该属于哪个分类，并给出一个离散的分类标签。除此之外，还有一类监督式学习算法，会根据一系列的特征输入，给出连续的预测值。

如果预估房屋的售价，达成这个预测目的的过程，需要最基本的**因变量连续回归分析**。

因变量连续回归的训练和预测，和分类的相应流程大体类似，不过具体采用的技术有一些不同。它采用的是研究一个或多个随机变量与另一些变量之间关系的统计方法，又称**多重回归分析**。

如果因变量和自变量为线性关系时，就成为**线性回归模型**；如果因变量和自变量为非线性关系，则称为**非线性回归分析模型**。

线性回归也是统计概率中常用的算法。

线性回归和其他算法相比，有很强的的可解释性。可以通过回归后为每个自变量确定的系数，来判那些自变量对最红的因变量影响大。可是，在正式开始线性回归分析之前，还有一个问题，那就是不同字段的数据没有可比性。

## 两种常见的特征变换方法

### 归一化

它其实就是获取原始数据的最大值和最小值，然后把原始值线性变换到[0,1]之间，变换函数为：

x'=(x-min)/(max-min)

其中x是原始值，max为样本数据的最大值，min为样本数据的最小值，x'是变换后的值。这种方法有个不足最大值与最小值非常容易受噪音数据的影响。

### 标准化

基于分布的z分数标准化。改方法假设数据呈现标准正态分布。

正态分布是连续随机变量概率分布的一种。在现实生活中，大量随机现象的数据分布都近似于正态分布。

**特点：**以经过平均数的垂线为轴，左右对称展开，中间点最高，然后逐渐向两侧下降，分布曲线和x轴组成的面积为1，表示不同事件出现的概率和为1.平均数和标准差是正态分布的关键参数，它们会决定分布的具体形态。而标准正态分布是正态分布的一种，平均数为0，标准差为1。

## 总结

**使用统计里的数据分布来进行特征值的转换：**

* 第一点，为什么有时候需要转换特征值？因为不同类型的特征值取值范围不同，分布也不同，相互之间没有可比性。因此在线性回归中，通过这些原始值分析得到的权重，并不能代表每个特征实际的重要性。
* 第二点，如何使用归一化进行特征值转换？这里的归一化是指使用特征取值范围中的最大值和最小值，把原始值转换为0到1之间的值。这样处理的好处在于简单易行，便于理解。不过，它的缺点也很明显，由于只考虑了最大最小值，因此很容易受到异常数据点的干扰。
* 第三点，如何使用标准化进行转换？经过标准化处理之后，每种特征的取值都会变成一个标准正态分布，以0为均值，1为标准差。和归一化相比，标准化使用了数据是正态分布的假设，不容易受到过大或过小值的干扰。

********







