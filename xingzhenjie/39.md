# 39 | 线性回归（上）：如何使用高斯消元求解线性方程组？

## 高斯消元法

对于回归分析来说，最简单的情形是只有一个自变量和一个因变量，且它们大体上是有线性关系的，这就是一元线性回归。

对应模型：**Y=a+bX+𝜺**

X是自变量，Y是因变量，a是截距，b是自变量的系数，𝜺表示随机误差。

高斯消元法主要分两步，**消元**和**回代**。所谓消元，就是要减少某些方程中元的数量。如果某个方程中的元只剩一个x𝓂了，那么这个自变量x𝓂的解就能知道了。所谓的回代，就是把已知的解x𝓂带入到方程式中，求出其他未知的解。

## 是用矩阵实现高斯消元法

<br><br><br><br>

## 总结

高斯消元法，包含两个步骤：消元和回代。这些步骤都可以使用矩阵进行操作。从矩阵的角度来说，消元就是把系数矩阵变为上三角矩阵，而回代是把这个上三角矩阵变为单位矩阵。可以直接把用于消元和回代的矩阵，用于由系数和因变量值组成的增广矩阵，并获得最终的方程解。

线性方程组的概念，也是线性回归分析的基础。在线性回归时，也能获得由很多观测数据值所组成的方程组。但是，在进行线性回归分析时，方程组的处理方式和普通的方程组求解有一些不同。有两个主要的区别。

* 第一个区别是，在线性回归分析中，样本数据会告诉我们自变量和因变量的值，要求的是系数。而在线性方程中，已知系数和因变量的值，要求的是自变量的值。
* 第二个区别是，在线性回归分析中，方程的数量要远远大于自变量的数量，而且不要求每个方程式都是完全成立。这里，不要求完全成立的意思里，拟合出来的因变量值可以和样本数据给定的因变量值存在差异，也就允许模型拟合存在误差。

**因此两点差异，无法直接使用消元法俩求解线性回归。**



********






