# 43 | PCA主成分分析（下）：为什么要计算协方差矩阵的特征值和特征向量？

## 基于Python的案例分析

>案例见教材

<br><br><br>

## PCA背后的核心思想

### 为什么要使用协方差矩阵？

**如何定义维度的信息量大小？**
这里认为样本在某个特征上的差异越大，那么这个特征包含的信息量就越大，就越重要。相反，信息量就越小，需要被过滤掉。使用某维特征的方差来定义样本在这个特征维度上的差异。

**如何发现荣誉的信息？**
如果两种特征是有很高的相关性，那么可以从一个维度的值推算出两一个维度的值，所表达的信息就是重复的。在实际运用中，可以使用皮尔森相关系数，来描述两个变量之间的线性相关程度。这个系数的取值范围是[-1，1]，绝对值越大，说明相关性越高，正数表示正相关，负数表示负相关。

**本质上，皮尔森相关系数和数据标准化后的协方差是一致的。**

考虑到协方差既可以衡量信息量的大小，也可以衡量不同维度之间的相关性，因此就使用各个维度之间的协方差所构成的矩阵，作为PCA分析的对象。这个协方差矩阵主对角线上的元素是各维度上的方差，也就体现了信息量，而其他元素是两两维度间的协方差，也就体现了相关性。

### 为什么要计算协方差矩阵的特征值和特征向量？

* 第一，对角矩阵。就是只有矩阵主对角线之上的元素有非0值，而其他元素的值都为0。
* 第二，特征值和特征向量的几何意义。在向量空间中，对某个向量左乘一个矩阵，实际上是对这个向量进行了一次变换。再变换过程中，被左乘的向量主要是发生旋转和伸缩两个变化。如果左乘矩阵对某一个向量或某些向量只发生伸缩变换，不对这些向量产生旋转的效果，那么这些向量就称为这个矩阵的特征向量，而伸缩的比例就是特征值。**某个矩阵的特征向量标示量这个矩阵在空间中的变化方向，这些方向都是趋于正交的，而特征值表示每个方向上伸缩的比例**

*******





