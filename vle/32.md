#### 32 | 概率统计篇答疑和总结：为什么会有欠拟合和过拟合？

#### 拟合、欠拟合和过拟合
每种学习模型都有自己的假设和参数。虽然朴素贝叶斯和决策树都属于分类算法，但是它们各自的假设和参数都不相同。
朴素贝叶斯的假设是贝叶斯定理和变量之间的独立性，而决策树的假设是集合的纯净程度或者混乱程度。
我们这里所说的参数，是指根据模型假设和训练样本推导出来的数据，例如朴素贝叶斯中的参数是各种先验概率和条件概率，而决策树的参数是各个树结点以及结点上的决策条件

> 根据测试数据的 x 轴取值（如图中的 x’）来获取 y 轴的取值（如图中的 y’），也就是根据自变量的值来获取因变量的值，达到预测的效果。这种情况就是适度拟合（right fitting）
有的时候拟合得到的模型过于简单，和训练样本之间的误差非常大，这种情况就是欠拟合（Under Fitting）。比如下面这根黑色的曲线，和第一根曲线相比，它离数据点的距离更大。这种拟合模型和训练样本之间的差异，我们就称为偏差（Bias）
> 相对于欠拟合，另一种情况是，拟合得到的模型非常精细和复杂，和训练样本之间的误差非常小，我们称这种情况为过拟合（Over Fitting）
>用于训练的数据都是苹果和甜橙，但是用于测试的数据都是西瓜。在上图中，测试数据 x’所对应的 y 值应该是 y’，而不是预测的 y’’。这种训练样本和测试样本之间存在的差异，我们称为方差（Variance）。在过拟合的时候，我们认为模型缺乏泛化的能力，无法很好地处理新的数据
>
#### 如何处理欠拟合和过拟合？
解释了什么是模型拟合、欠拟合和过拟合，我们下面来说说，有哪些常见的处理过拟合和欠拟合的方法

欠拟合问题，产生的主要原因是特征维度过少，拟合的模型不够复杂，无法满足训练样本，最终导致误差较大

> 相对应的，过拟合问题产生的主要原因则是特征维度过多，导致拟合的模型过于完美地符合训练样本，但是无法适应测试样本或者说新的数据。所以我们可以减少特征的维度。之前在介绍决策树的时候，我提到了这类算法比较容易过拟合，可以使用剪枝和随机森林来缓解这个问题
条件概率、联合概率和边缘概率体现了多个随机变量之间的关系以及是不是相互独立，通过这三者的关系，可以推导出贝叶斯定理
