17 | 时间和空间复杂度（下）：如何使用六个法则进行复杂度分析？

#### 案例分析一：广度优先搜索
我们先快速回顾一下搜索的主要步骤
 * 第一步，判断边界条件，时间和空间复杂度都是 O(1)。
 * 第二步，生成空的队列。常量级的 CPU 和内存操作，根据主次分明法则，时间和空间复杂度都是 O(1)
 * 第三步，把搜索的起始结点放入队列 queue 和已访问结点的哈希集合 visited，类似上一步，常量级操作，时间和空间复杂度都是 O(1)
 * 第四步，也是最核心的步骤，包括了 while 和 for 的两个循环嵌套。
 
 看时间复杂度：
 根据四则运算法则,时间复杂度是两个循环的次数相乘

* 第一个关键点双向搜索所要走的边数。如果单向需要走 l 条边，那么双向是 l/2。因此时间和空间复杂度都会变为 O(2*m^(l/2)，简写为 O(m^(l/2))。这里 l/2 中的 2 不能省去，因为它是在指数上，改变了数量级。仅从这点来看，双向比单向的复杂度低
* 第二个关键点是双向搜索过程中，判断是否找到通路的方式。单向搜索只需要判断一个点是否存在集合中，每次只有 O(1) 的复杂度。而双向搜索需要比较两个集合是否存在交集，复杂度肯定要高于 O(1)。最常规的实现方法是，循环遍历其中一个集合 A，看看 A 中的每个元素是不是出现在集合 B 中。假设两个集合中元素的数量都为 n，那么循环 n 次，那么时间复杂度就为 O(n)

#### 案例分析二：全文搜索
* 第一，把全文作为一个很长的字符串，把用户输入的关键词作为一个子串，那这个搜索问题就变成了子串匹配的问题。假设字符串平均长度为 n 个字符，关键词平均长度为 m 个字符，使用最简单的暴力法，就是把代表全文的字符串的每个字符，和关键词字符串的每个字符两两相比，那么时间复杂度就是 O(n*m)
* 第二，对全文进行分词，把全文切分成一个个有意义的词，那么这个搜索问题就变成了把输入关键词和这些切分后的词进行匹配的问题
