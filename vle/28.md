#### 28 | 熵、信息增益和卡方：如何寻找关键特征？
#### 什么是特征选择？
机器学习有十分广泛的应用:监督式学习,非监督式的学习
* 监督式学习，是指通过训练资料学习并建立一个模型，并依此模型推测新的实例，主要包括分类（Classification）和回归（Regression）
> 机器学习的步骤主要包括数据的准备、特征工程、模型拟合、离线和在线测试
“特征”（Feature），是机器学习非常常用的术语，它其实就是可用于模型拟合的各种数据

#### 利用信息熵进行特征选择
使用词包（Bag of Words）模型和分词，把完整的文章切分成多个单词或词组，而它们就表示了文章的关键属性，也就是用于机器学习的特征。
* 首先，我们来看这个问题，什么是对分类有价值的特征？
如果一个特征，经常只在某个或少数几个分类中出现，而很少在其他分类中出现，那么说明这个特征具有较强的区分力，它的出现很可能预示着整个数据属于某个分类的概率很高或很低

#### 利用卡方检验进行特征选择
卡方检验考虑了四种情况的概率：P(fi​,cj​) 、P(fi​ˉ​,cj​ˉ​)、P(fi​,cj​ˉ​) 和 P(fi​ˉ​,cj​)。
在这四种概率中，P(fi​,cj​) 和 P(fi​ˉ​,cj​ˉ​) 表示特征 fi​ 和分类 cj​ 是正相关的。
如果 P(fi​,cj​) 很高，表示特征 fi 的出现意味着属于分类 cj​ 的概率更高；
如果 P(fi​ˉ​,cj​ˉ​) 很高，表示特征 fi​ 不出现意味着不属于分类 cj​ 的概率更高。
类似地，P(fi​,cj​ˉ​) 和 P(fi​ˉ​,cj​) 表示特征 fi​ 和分类 cj​ 是负相关的。
如果 P(fi​,cj​ˉ​) 很高，表示特征 fi​ 的出现意味着不属于分类 cj​ 的概率更高；如果 P(fi​ˉ​,cj​) 很高，表示特征 fi​ 不出现意味着属于分类 cj​ 的概率更高。
