#### 50 | 推荐系统（下）：如何通过SVD分析用户和物品的矩阵？
推荐系统是个很大的课题，你可以尝试不同的想法

#### SVD 回顾以及在推荐中的应用
在实现 SVD 分解之前，我们先来回顾一下 SVD 的主要概念和步骤。如果矩阵 X 是对称的方阵，那么我们可以求得这个矩阵的特征值和特征向量，并把矩阵 X 分解为特征值和特征向量的乘积

假设我们求出了矩阵 X 的 n 个特征值 λ1​，λ2​，…，λn​，以及这 n 个特征值所对应的特征向量 v1​，v2​，…，vn​，那么矩阵 X 可以表示为

X=VΣV−1
其中，V 是这 n 个特征向量所张成的 n×n 维矩阵，而 Σ 是这 n 个特征值为主对角线的 n×n 维矩阵。这个过程就是特征分解（Eigendecomposition）

如果我们会把 V 的这 n 个特征向量进行标准化处理，那么对于每个特征向量 Vi​，就有 ∣∣Vi​∣∣2​=1，而这表示 V’i​Vi​=1，此时 V 的 n 个特征向量为标准正交基，满足 V’V=I， 也就是说，V 为酉矩阵，有 V’=V−1 。这样一来，我们就可以把特征分解表达式写作：X=VΣV′

第二种方式是通过 X’X 矩阵或者 XX’ 矩阵的特征值之平方根，来求奇异值。计算出每个奇异值 σ，那么就能得到奇异值矩阵 Σ 了

最终，SVD 分解把原来的“词条 - 文档”关系，转换成了“词条 - 语义概念 - 文档”的关系。而在推荐系统的应用场景下，对用户评分矩阵的 SVD 分解，能够帮助我们找到电影中潜在的“主题”，比如科幻类、动作类、浪漫类、传记类等等。分解之后所得到的奇异值 σ 对应了一个“主题”，σ 值的大小表示这个主题在整个电影集合中的重要程度。U 中的左奇异向量表示了每位用户对这些“主题”的喜好程度，V 中的右奇异向量表示每部电影和这些“主题”的关系强弱。最终，SVD 分解把原来的“用户 - 电影”关系，转换成了“用户 - 主题 - 电影”的关系。有了这种新的关系，即使我们没有人工标注的电影类型，同样可以使用更多基于电影主题的推荐方法，比如通过用户对电影主题的评分矩阵，进行基于用户或者电影的协同过滤


#### 总结
在今天的内容中，我们回顾了 SVD 奇异值分解的核心思想，解释了如何通过 XX’ 和 X’X 这两个对称矩阵的特征分解，求得分解后的 U 矩阵、V 矩阵和 Σ 矩阵。另外，我们也解释了在用户对电影评分的应用场景下，SVD 分解后的 U 矩阵、V 矩阵和 Σ 矩阵各自代表的意义，其中 Σ 矩阵中的奇异值表示了 SVD 挖掘出来的电影主题，U 矩阵中的奇异向量表示用户对这些电影主题的评分，而 V 矩阵中的奇异向量表示了电影和这些主题的相关程度。我们还通过 Python 代码，实践了这种思想在推荐算法中的运用。从结果的奇异值和奇异向量可以看出，SVD 分解找到了一些 MovieLens 数据集上的电影主题。这样我们就可以把用户针对电影的评分转化为用户针对主题的评分。由于主题通常远远小于电影，所以 SVD 的分解也帮助我们实现了降低特征维度的目的。SVD 分解能够找到一些“潜在的“因素，例如语义上的概念、电影的主题等等。虽然这样操作可以降低特征维度，去掉一些噪音信息，但是由于 SVD 分解本身的计算量也很大，所以从单次的执行效率来看，SVD 往往无法起到优化的作用。在这种情况下，我们可以考虑把它和一些监督式的学习相结合，使用一次分解的结果构建分类器，提升日后的执行效率
