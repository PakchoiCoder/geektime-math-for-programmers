#### 29 | 归一化和标准化：各种特征如何综合才是最合理的？

#### 为什么需要特征变换？
我们之前介绍的监督式学习会根据某个样本的一系列特征，最后判定它应该属于哪个分类，并给出一个离散的分类标签。
除此之外，还有一类监督式学习算法，会根据一系列的特征输入，给出连续的预测值

因变量连续回归的训练和预测，和分类的相应流程大体类似，不过具体采用的技术有一些不同。它采用的是研究一个或多个随机变量 y1​，y2​，…，yi​ 与另一些变量 x1​，x2​，…，xk​ 之间关系的统计方法，又称多重回归分析

> 因变量和自变量为线性关系时，就称为线性回归模型,如果因变量和自变量为非线性关系，则称为非线性回归分析模型

线性回归和其他算法相比，有很强的可解释性。
我们可以通过回归后为每个自变量确定的系数，来判哪些自变量对最终的因变量影响更大。
可是，在正式开始线性回归分析之前，还有一个问题，那就是不同字段的数据没有可比性

#### 两种常见的特征变换方法
归一化我们先来看最常用的方法，归一化（Normalization）。
它其实就是获取原始数据的最大值和最小值，然后把原始值线性变换到 [0,1] 之间，具体的变换函数为
其中 x 是原始值，max 为样本数据的最大值，min 为样本数据的最小值，x’ 是变换后的值。
这种方法有个不足最大值与最小值非常容易受噪音数据的影响

#### 标准化
另一种常见的方法是基于正态分布的 z 分数（z-score）标准化（Standardization）。
该方法假设数据呈现标准正态分布。什么是标准正态分布呢？我们之前介绍过，正态分布是连续随机变量概率分布的一种。
在现实生活中，大量随机现象的数据分布都近似于正态分布
```
x` =(x-u)/q
```

* 第一点，为什么有时候需要转换特征值？因为不同类型的特征取值范围不同，分布也不同，相互之间没有可比性。因此在线性回归中，通过这些原始值分析得到的权重，并不能代表每个特征实际的重要性。
* 第二点，如何使用归一化进行特征值转换？这里的归一化是指使用特征取值范围中的最大值和最小值，把原始值转换为 0 到 1 之间的值。这样处理的好处在于简单易行，便于理解。不过，它的缺点也很明显，由于只考虑了最大最小值，因此很容易受到异常数据点的干扰。
* 第三点，如何使用标准化进行转换？经过标准化处理之后，每种特征的取值都会变成一个标准正态分布，以 0 为均值，1 为标准差。和归一化相比，标准化使用了数据是正态分布的假设，不容易受到过大或过小值的干扰

