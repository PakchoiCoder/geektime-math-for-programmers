# 35 | 文本检索：如何让计算机处理自然语言？

## 什么是信息检索？

信息检索就是让计算机根据用户信息需求，从大规模、非结构化的数据中，找出相关的资料。

非结构化”其实是针对经典的关系型数据库，数据库里的记录都有严格的字段定义（Schema），是“结构化”数据的典型代表。

“非结构化”没有这种严格的定义，互联网世界里所存储的海量文本就是“非结构化“数据的典型代表。

## 布尔模型

最简单的模型是布尔模型，它借助了逻辑（布尔）代数的基本思想。

如果有，就相当于返回值为“真”，我就认为这篇文章就是相关的。如果没有，就相当于返回值为“假”，我就认为这篇文章不相关。这就是布尔模型的核心思想。

## 向量空间模型

将文档转换为向量，然后比较向量之间的距离或者相似程度。

使用词包（Bag Of Word）的方式，忽略了单词在文章中出现的顺序，简化计算复杂度。类似地，这个模型也会把用户输入的查询转换为向量。

转化为计算查询向量和文档向量之间的距离或者相似度了。距离越小或者说相似度越高，那么我们就认为相关度越高。


相对于标准的布尔数学模型，向量空间模型的主要优势在于，允许文档和查询之间的部分匹配


## 信息检索中的向量空间模型

第一步，把文档集合都转换成向量的形式。

第二步，把用户输入的查询转换成向量的形式，然后把这个查询的向量和所有文档的向量，进行比对，计算出基于距离或者夹角余弦的相似度。

第三步，根据查询和每个文档的相似度，找出相似度最高的文档，认为它们是和指定查询最相关的。

第四步，评估查询结果的相关性。

### 把文档转为特征向量

维度和取值。这里的维度表示向量有多少维分量、每个分量的含义是什么，而取值表示每个分量的数值是多少。




- 把文章中唯一的单词或者词组，作为向量的一个维度。

>如何基于词包（Bag of Word）的方式来预处理文本，包括针对中文等语系的分词操作、针对英文等拉丁语系的词干（Stemming）和归一化（Normalization）处理，以及所有语言都会碰到的停用词（Stopword）、同义词和扩展词处理。

可以获得每篇文档出现的单词和词组。而通过对所有文档中的单词和词组进行去重，我们就可以构建整个文档集合的词典（Vocabulary）。向量空间模型把词典中的每个词条作为向量的一个维度。

- 维度需要取什么值

考虑每个维度需要取什么值。最简单的方法是用“1”表示这个词条出现在文档中，“0”表示没有出现。不过这种方法没有考虑每个词的权重。有些词经常出现，它更能表达文章的主要思想，

基于词频的方法

- 方法1

假设我们有一个文档集合 c，d 表示 c 中的一个文档，t 表示一个单词，那么我们使用 tf 表示词频（Term Frequency），也就是一个词 t 在文档 d 中出现的次数。这种方法的假设是，如果某个词在文档中的 tf 越高，那么这个词对于这个文档来说就越重要。

- 方法2

另一种改进方法，不仅考虑了 tf，还考虑了 idf。这里 idf 表示逆文档频率（Inverse Document Frequency）。首先，df 表示文档频率（Document Frequency），也就是文档集合 c 中出现某个词 t 的文档数量。一般的假设是，某个词 t 在文档集合 c 中，出现在越多的文档中，那么其重要性越低，反之则越高。


## 查询和文档的匹配

在计算查询和文档的相似度之前，我们还需要把查询转换成向量。由于用户的查询也是由自然语言组成，所以这个转换的流程和文档的转换流程是基本一致的

- 第一，查询和文档长度不一致。
- 第二，查询里出现了文档集合里没有的词
- 第三，查询里词条的 idf 该如何计算。
