# 26 | 信息熵：如何通过几个问题，测出你对应的武侠人物？

## 信息熵

假设两道题目，一道题目可以将特定人群分成 50% 和 50%，另一道题目可以分成 80% 和 20%，就可以说第一道题目的区分能力比第二道强。我们用信息熵（Entropy）和信息增益（Information Gain），来衡量每道题目的区分能力。

信息熵，其实就是用来刻画给定集合的纯净度的一个指标。每个 item 都有一个分类，有多个分类，当一个集合中，所有 item 只有一个分类，那么就可以说这个最为纯净，熵为 0。如果一个集合混入了其他分类的 item，那么纯净度就不纯，熵就是大于 0 的。

反过来，当我们有一个集合，想要对里面的内容进行分类，分出最终的 item，必须通过设置一些条件来进行，那么分类效果怎么比较和衡量？就需要通过熵的计算来衡量。计算公式如下：

![](https://static001.geekbang.org/resource/image/f9/c0/f9da465b8601bb84b97022afd88cbac0.png)

其中，n 表示集合中分组的数量，pi​ 表示属于第 i 个分组的元素在集合中出现的概率。

之后我们将集合按照某个条件分成多个集合，已知每个集合熵的算法，如何计算拆分之后的整体熵？可以使用下面公式：

![](https://static001.geekbang.org/resource/image/cd/d3/cd8f5873383759df7782b37f125bb1d3.png)

这个公式其实就表示，对于多个小集合而言，其整体的熵等于各个小集合之熵的加权平均。

## 信息增益

假设整个集合的熵为 3，按照某个特定条件分类之后，整体熵变成了 2，这个降低的差值就是信息增益。如果划分后，整体熵下降的越多，信息增益就越大，公式如下：

![](https://static001.geekbang.org/resource/image/72/79/7268dcacc996164ba51a499db45de679.png)

如果熵差值越大，表示信息增益越多，相比之下应该选择这个分类条件。

以实际的问题 case 来看，我们可以以此安排测试问题的先后顺序，先用信息赠一找出区分能力最强的测试题，然后放在前面。

## 思考题

`P = -64 * 0.015625 * log(0.015625, 2) = 6`，2 的 6 次方正好是 64。
