# 50 | 推荐系统（下）：如何通过 SVD 分析用户和物品的矩阵？

对于用户给电影评分的案例，也可以用 SVD 奇异值的分解，来分解用户评分的矩阵，找到潜在的电影主题。

## 回顾 SVD

如果矩阵 X 是对称的方阵，那么我们可以求得这个矩阵的特征值和特征向量，并把矩阵 X 分解为特征值和特征向量的乘积。这个过程就是特征分解（Eigendecomposition）

之后我们会对分解出来的特征向量进行标准化处理。但如果矩阵 X 不是对称的方阵，那么不一定能得到有实数解的特征分解，SVD 可以避免这个问题。

我们可以把 X 的转置 X’ 和 X 做矩阵乘法，得到一个 n×n 维的对称方阵 X’X，并对这个对称方阵进行特征分解。分解的时候，我们得到了矩阵 X’X 的 n 个特征值和对应的 n 个特征向量 v，其中所有的特征向量叫作 X 的右奇异向量。通过所有右奇异向量我们可以构造一个 n×n 维的矩阵 V。

类似地，如果我们把 X 和 X’ 做矩阵乘法，那么会得到一个 m×m 维的对称方阵 XX’。由于 XX’ 也是方阵，因此我们同样可以对它进行特征分解，并得到矩阵 XX’ 的 m 个特征值和对应的 m 个特征向量 u，其中所有的特征向量向叫作 X 的左奇异向量。通过所有左奇异向量我们可以构造一个 m×m 的矩阵 U。

现在，包含左右奇异向量的 U 和 V 都求解出来了，只剩下奇异值矩阵 Σ 了。Σ 除了对角线上是奇异值之外，其他位置的元素都是 0，所以我们只需要求出每个奇异值 σ 就可以了。一旦我们求出了每个奇异值 σ，那么就能得到奇异值矩阵 Σ。

在潜在语义分析 LSA 的应用场景下，分解之后所得到的奇异值 σ，对应一个语义上的“概念”，而 σ 值的大小表示这个概念在整个文档集合中的重要程度。U 中的左奇异向量表示了每个文档和这些语义“概念”的关系强弱，V 中的右奇异向量表示每个词条和这些语义“概念”的关系强弱。最终，SVD 分解把原来的“词条 - 文档”关系，转换成了“词条 - 语义概念 - 文档”的关系。而在推荐系统的应用场景下，对用户评分矩阵的 SVD 分解，能够帮助我们找到电影中潜在的“主题”，比如科幻类、动作类、浪漫类、传记类等等。

## 总结

SVD 分解后的 U 矩阵、V 矩阵和 Σ 矩阵各自代表的意义：Σ 矩阵中的奇异值表示了 SVD 挖掘出来的电影主题，U 矩阵中的奇异向量表示用户对这些电影主题的评分，而 V 矩阵中的奇异向量表示了电影和这些主题的相关程度。

SVD 分解能够找到一些“潜在的“因素，例如语义上的概念、电影的主题等等。虽然这样操作可以降低特征维度，去掉一些噪音信息，但是由于 SVD 分解本身的计算量也很大，所以从单次的执行效率来看，SVD 往往无法起到优化的作用。在这种情况下，我们可以考虑把它和一些监督式的学习相结合，使用一次分解的结果构建分类器，提升日后的执行效率。
