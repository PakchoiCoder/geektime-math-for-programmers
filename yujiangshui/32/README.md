# 32 | 概率统计篇答疑和总结：为什么会有欠拟合和过拟合？

## 拟合、欠拟合和过拟合

在监督式学习中，我们经常提到“训练一个模型”，其实更学术的说法是“拟合一个模型”。

拟合模型其实就是通过模型的假设和训练样本，推导出具体参数的过程。之后我们就能对新的数据进行预测。

如果模型过于简单，训练样本之间误差较大，就是欠拟合，所以就会产生偏差。相反的是过拟合，强行拟合所有样本，导致无法精准预测未来数据，虽然在训练样本中表现的非常优越。

偏差和方差可以表示拟合的结果：

- 欠拟合：高偏差、低方差
- 适度拟合：偏差和方差适度
- 过拟合：低偏差、高方差

## 如何处理欠拟合和过拟合？

**欠拟合原因是特征维度过少，拟合的模型不够复杂，无法满足训练样本，最终导致误差较大。解决方法：增加特征维度，让输入的训练样本具有更强的表达能力。**

比如朴素贝叶斯的前提是“任何两个变量是相互独立的假设”但现实场景中往往不成立，所以朴素贝叶斯模型的表达能力是非常有限的。如果有足够的素材和计算资源，就可以增加更多特征来提升模型复杂度使其拟合。

**过拟合的问题产生原因是特征维度过多，导致拟合的模型过于完美的符合训练样本，但是无法适应测试样本或者说新的数据。所以我们可以减少特征的维度。**

比如之前说的剪枝的策略，删除掉决策树中一些不是很重要的结点和对应的边，这其实就是减少特征对模型的影响，使其具备更好的泛化能力。

随机森林的构建过程更复杂，用一套训练样本随机采样然后构建一颗决策树，这样可以有若干决策树，对于新的数据，每个决策树都有自己的判断结果，我们取大多数决策树的意见。这样就会降低每个决策树的过拟合程度。

此外过拟合表示模型复杂而训练数据量不足以训练如此复杂的模型，所以也可以增加训练样本的数据量。还可以使用交叉验证等划分方式来保持训练数据和测试数据的一致性。拿出大部分数据建模，然后利用小部分实例进行预测验证然后评估。

此外还需要定期更新训练样本，重新拟合模型。
