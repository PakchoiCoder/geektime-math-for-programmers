# 40 | 线性回归（中）：如何使用最小二乘法进行直线拟合？

求解线性回归和普通的线性方程组最大的不同在于误差 ε。我们要做的就是尽量把 ε 最小化，并控制在一定范围之内。这样我们就可以求方程的近似解。

在线性回归中，为了实现最小化 ε 的目标，我们可以使用最小二乘法进行直线的拟合。最小二乘法通过最小化误差的平方和，来寻找和观测数据匹配的最佳函数。

简单的说，我们进行数据分析和寻找拟合函数时，会得到多个函数，通过最小二乘法计算出来的误差平方和，就可以得知哪个函数比较精准从而选用这个模型。

## 使用观测值拟合

在监督式学习中，拟合模型其实是指通过模型的假设和训练样本，推导出具体参数的过程。有了这些参数，我们就能对新的数据进行预测。而在线性回归中，我们需要找到观测数据之间的线性关系。

假设有很多点，需要选一条直线可以离个个点都比较近，如何处理？

首先精确的线肯定无法得知，无法有一条线可以完全精准穿过所有点，只能求近似值。

## 最小二乘法

主要思想就是求解位置参数，使得理论值与观测值之差（即误差，或者说残差）的平方和达到最小。

![](https://static001.geekbang.org/resource/image/82/f8/82c94c629f2cb09dff9a8014186b84f8.png)

其实就是每个点的实际值到函数产生的理论值的差距的平方和的数量，这样可以得到整个数据集跟当前函数的差别。

有了定义，就可以写出最小二乘问题的矩阵形式：

min∣∣XB−Y∣∣22​

其中 B 为系数矩阵，X 为自变量矩阵，Y 为因变量矩阵。换句话说，我们要在向量空间中，找到一个 B，使向量 XB 与 Y 之间欧氏距离的平方数最小的 B。

todo 学习极值、求导等

## 总结

简单的线性方程组无法满足线性函数拟合的需求，最主要的原因就是现实的观测数据往往不是精确的线性关系，存在一定的误差。我们所要做的就是，在允许一定范围的误差前提下，找到一种线性关系，尽量的满足观察数据，使得我们所定义的误差最小。

最小二乘法通过向量空间的欧氏距离之平方，定义了预测值和真实值之间的误差。在给定自变量和因变量的观测值之后，最小二乘法可以帮助我们推导出所有自变量的系数，并最小化误差。
